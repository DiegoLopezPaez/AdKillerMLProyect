{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1649014766050,
     "user": {
      "displayName": "Diego López",
      "userId": "15812219008632119568"
     },
     "user_tz": 180
    },
    "id": "cdyK4rrXMBUo"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "#from google.colab import drive\n",
    "import os\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaC_Te7NPcdO"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1649014766368,
     "user": {
      "displayName": "Diego López",
      "userId": "15812219008632119568"
     },
     "user_tz": 180
    },
    "id": "K2kDacKOPpda"
   },
   "outputs": [],
   "source": [
    "#Frecuencia en la cual se tomaran muestras en un audio\n",
    "frecuencia_muestra = 22050\n",
    "#TODO\n",
    "#Este valor hay que cambiarlo, ya que todos los audios no tienen la misma duracion, hay que solucionar este problema...\n",
    "#asumimos que todos tienen 10 segundos\n",
    "duracion_audio = 10 #En segundos\n",
    "num_de_muestras_por_audio = frecuencia_muestra * duracion_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1821,
     "status": "ok",
     "timestamp": 1649014768175,
     "user": {
      "displayName": "Diego López",
      "userId": "15812219008632119568"
     },
     "user_tz": 180
    },
    "id": "kWkskPu-MPhT",
    "outputId": "76d41250-1043-450d-9496-6455e7705e4e"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649014768176,
     "user": {
      "displayName": "Diego López",
      "userId": "15812219008632119568"
     },
     "user_tz": 180
    },
    "id": "Uba4R_Q0MSt6"
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#Definir los path de los audios, tendriamos que tener dos, el de conversacion y el de no_conversacion\n",
    "folder_path = \"audio_files_cut\" #path a la carpeta de los audios. C:\\Users\\Usuario\\Desktop\\MACHINELEARNINGPROYECT\n",
    "json_path = \"json_data_audio_cut.json\" #path al archivo json donde guardar los datos extraidos de los audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "#preparamos el audio\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def recortar_audio(carpetA, carpetaB, duracion):\n",
    "    # Verificar si la carpeta de destino existe, si no, crearla\n",
    "    if not os.path.exists(carpetaB):\n",
    "        os.makedirs(carpetaB)\n",
    "\n",
    "    # Obtener la lista de archivos en la carpeta A\n",
    "    archivos = os.listdir(carpetA)\n",
    "\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith(\".mp3\") or archivo.endswith(\".wav\"):\n",
    "            # Cargar el archivo de audio\n",
    "            audio = AudioSegment.from_file(os.path.join(carpetA, archivo))\n",
    "\n",
    "            # Dividir el audio en segmentos de la duración especificada (en milisegundos)\n",
    "            segmentos = [audio[i:i+duracion*1000] for i in range(0, len(audio), duracion*1000)]\n",
    "\n",
    "            # Guardar los segmentos en la carpeta B\n",
    "            for i, segmento in enumerate(segmentos):\n",
    "                nombre_archivo = f\"{os.path.splitext(archivo)[0]}_segmento_{i+1}.wav\"\n",
    "                segmento.export(os.path.join(carpetaB, nombre_archivo), format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso:\n",
    "carpeta_origen = \"audio_files\\\\c_\"\n",
    "carpeta_destino = \"audio_files_cut\"\n",
    "duracion_segmento = 10  # Duración en segundos\n",
    "\n",
    "recortar_audio(carpeta_origen, carpeta_destino, duracion_segmento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tABRiVHUGehJ"
   },
   "source": [
    "Este paso se hace primero para obtener un json con la informacion de los audios, ya que realizar la operacion de extraccion de datos cuesta tiempo, entonces se extrae una vez y luego se usa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_zeroes(matrix):\n",
    "  #  if(matrix.tolist()[-1][-1] == 0):\n",
    "       # print(\"----------\")\n",
    "       # print(matrix)\n",
    "       # print(\"----------\")\n",
    "       # print()\n",
    "       # print()\n",
    "    for lista in matrix.tolist():\n",
    "        if(lista[-1] == 0):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649014768176,
     "user": {
      "displayName": "Diego López",
      "userId": "15812219008632119568"
     },
     "user_tz": 180
    },
    "id": "w-ucm2DPMf-l"
   },
   "outputs": [],
   "source": [
    "def save_mfcc(path_datos, json_path, n_mfcc = 13, n_fft = 2048, hop_length = 512, num_segmentos = 2):\n",
    "  \n",
    "  #diccionario para almacenar datos\n",
    "    data = {\n",
    "      \"categoria\": [], #Esto tendra la categoria del audio: conversacion o no_conversacion\n",
    "      \"mfcc\": [], #Seria el input train, tendra todos los valores del mfcc\n",
    "      \"labels\": [] #Seria el output, esta relacionado con a que categoria representa un mfcc\n",
    "    }\n",
    "    \n",
    "    bad_data = {\n",
    "        \"categoria\": [], #Esto tendra la categoria del audio: conversacion o no_conversacion\n",
    "        \"mfcc\": [], #Seria el input train, tendra todos los valores del mfcc\n",
    "        \"labels\": [] \n",
    "    }\n",
    "\n",
    "  \n",
    "    num_de_muestras_por_segmento = int(num_de_muestras_por_audio / num_segmentos) \n",
    "  \n",
    "  #Como necesitamos que todos los valores de entrenamiento del modelo tengan la misma forma\n",
    "  #definimos un numero fijo de vectores mfcc a utilizar.\n",
    "    num_de_vectores_mfcc_por_segmento = math.ceil(num_de_muestras_por_segmento / hop_length)\n",
    "\n",
    "  #TODO\n",
    "  #COMO TENEMOS DOS FUENTES DE DATOS, VER DE SHUFFLEAR AL FINAL POR LAS DUDAS DE QUE NO SE USEN CORRECTAMENTE LOS DATOS\n",
    "  #AL MOMENTO DEL ENTRENAMIENTO\n",
    "\n",
    "  #dirpath: el path del directorio actual\n",
    "  #dirname: el nombre del directorio\n",
    "  #filenames: los nombres de los archivos del directorio\n",
    "  #indice tiene el numero de la iteracion, que representara el genero\n",
    "    for indice, (dirpath, dirnames, filenames) in enumerate(os.walk(folder_path)):\n",
    "\n",
    "    #No queremos estar en la carpeta principal, sino en la de los generos que tiene los audios\n",
    "        if dirpath is not folder_path:\n",
    "\n",
    "      #separamos el path por cada / en el path en un array y agarramos el ultimo, que seria la categoria \n",
    "            folder_categoria = dirpath.split(\"\\\\\")[-1]\n",
    "            data[\"categoria\"].append(folder_categoria)\n",
    "            bad_data[\"categoria\"].append(folder_categoria)\n",
    "      #print(f\"\\nProcesando {folder_genero}\")\n",
    "\n",
    "      #Obtenemos los audios del directorio\n",
    "            for audio_name in filenames:\n",
    "\n",
    "                audio_path = os.path.join(dirpath, audio_name)\n",
    "                signal, sr = librosa.load(audio_path, sr=frecuencia_muestra)\n",
    "\n",
    "        #TODO\n",
    "        #Otra consideracion, como la duracion de los audios de ruido ya es corta (5 seg)\n",
    "        #Pensamos dejar el recorte solamente para los demas audios\n",
    "        \n",
    "        #Como tenemos pocos datos, vamos a dividir el procesamiento de los\n",
    "        #audios en diferentes segmentos, entonces para un audio tendriamos\n",
    "        #varios segmentos del mismo para usar como datos de entrenamiento\n",
    "        #o testeo.\n",
    "                for segmento in range(num_segmentos):\n",
    "\n",
    "          #definimos el inicio y final del actual segmento\n",
    "                    inicio_de_muestra = num_de_muestras_por_segmento * segmento \n",
    "                    fin_de_muestra = inicio_de_muestra + num_de_muestras_por_segmento\n",
    "\n",
    "              # Extraemos el mfcc solo del intervalo definido arriba.\n",
    "                    if(inicio_de_muestra < signal.size and fin_de_muestra < signal.size):\n",
    "                        mfcc = librosa.feature.mfcc(y=signal[inicio_de_muestra: fin_de_muestra],\n",
    "                                              sr=sr,\n",
    "                                              n_fft = n_fft,\n",
    "                                              n_mfcc = n_mfcc,\n",
    "                                              hop_length = hop_length)\n",
    "\n",
    "\n",
    "                        mfcc = mfcc.T\n",
    "#                print(mfcc)\n",
    "#                print()\n",
    "#                print()\n",
    "#                print(mfcc.tolist())\n",
    "#                print()\n",
    "#                print()\n",
    "#                print(mfcc.tolist()[-1][-1])\n",
    "#                print()\n",
    "#                print()\n",
    "#                break\n",
    "                        if len(mfcc) == num_de_vectores_mfcc_por_segmento and not has_zeroes(mfcc):\n",
    "                            data[\"mfcc\"].append(mfcc.tolist())\n",
    "                            data[\"labels\"].append(indice - 1)\n",
    "                        else:\n",
    "                            bad_data[\"mfcc\"].append(mfcc.tolist())\n",
    "                            bad_data[\"labels\"].append(indice - 1)\n",
    "                    #print(f\"{audio_path}, segmento:{segmento}\")\n",
    "  \n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "    \n",
    "    with open(\"bad_data_cut.json\", \"w\") as fp:\n",
    "        json.dump(bad_data, fp, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217319,
     "status": "ok",
     "timestamp": 1649014985489,
     "user": {
      "displayName": "Diego López",
      "userId": "15812219008632119568"
     },
     "user_tz": 180
    },
    "id": "eOef9xNL4_Rh",
    "outputId": "fd635940-d524-4b01-8adb-2bff2fa6ace9"
   },
   "outputs": [],
   "source": [
    "save_mfcc(path_datos = folder_path, json_path=json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPB/CxfbueJJ4WP6fnLdYBK",
   "collapsed_sections": [],
   "name": "ObtencionDeDatosDeGenerosMusicales.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
